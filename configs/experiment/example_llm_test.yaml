# @package _global_

defaults:
  - override /trainer: gpu
  - override /data: all_text
  - override /callbacks: llm_callbacks
  - override /model: llm
  - override /logger: default

trainer:
  max_epochs: 3

project_name: 'Causal LLM Experiment'
task_name: 'LLM_Judge'
compile: False # we can only compile on GPU
phase: 'train'

tokenizer:
  _target_: src.datasets.Tokenizer
  checkpoint: "distilbert/distilgpt2"
  max_length: null

# Shorten epochs to 100 samples
data:
  batch_size: 1
  shuffle: False
  num_workers: 8
  sampler:
    _target_: torch.utils.data.SubsetRandomSampler
    indices:
      _target_: builtins.range
      _args_: [100]

logger:
  log_model: False

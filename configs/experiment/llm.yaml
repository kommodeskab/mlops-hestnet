# @package _global_

defaults:
  - override /trainer: cpu
  - override /data: all_text
  - override /callbacks: llm_callbacks
  - override /model: muon
  - override /logger: default

project_name: 'Causal LLM Experiment'
task_name: 'test'
compile: False # we can only compile on GPU
phase: 'train'

tokenizer:
  _target_: src.datasets.Tokenizer
  checkpoint: "distilbert/distilgpt2"
  max_length: null

data:
  batch_size: 1

logger:
  log_model: True
